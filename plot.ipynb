{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program can work with any of the four datasets with minor modifications. This program is adapted for the relabeled version of the mixed-label dataset. The program is written and commented with the help of ChatGPT and Copilot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "with open('true_labels_30.p', 'rb') as file:\n",
    "    all_true_labels = pickle.load(file)\n",
    "\n",
    "with open('GRU_test_30.p', 'rb') as file:\n",
    "    bigru_logits = pickle.load(file)\n",
    "\n",
    "\n",
    "with open('T5_test_30.p', 'rb') as file:\n",
    "    t5_logits = pickle.load(file)\n",
    "\n",
    "\n",
    "# now load the data from the file\n",
    "with open('CNN_test_30.p', 'rb') as file:\n",
    "    CNN_logits = pickle.load(file)\n",
    "\n",
    "# load norbert logits\n",
    "with open('NorBERT_test_30.p', 'rb') as file:\n",
    "    norbert_logits = pickle.load(file)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "\n",
    "# create list for plotting for Norbert and CNN\n",
    "all_logits = np.concatenate((norbert_logits, CNN_logits), axis=0)\n",
    "all_logits.shape\n",
    "# Get the shape of all_logits\n",
    "shape = all_logits.shape\n",
    "i =1\n",
    "f1_list_NorBERT_CNN = []\n",
    "ac_list_NorBERT_CNn = []\n",
    "recall_list_NorBERT = []\n",
    "precision_list_NorBERT_CNN = []\n",
    "\n",
    "# Select two random indices\n",
    "for i in range(1,16):\n",
    "    \n",
    "    f1_list_NorBERT_CNN.append([])\n",
    "    ac_list_NorBERT_CNn.append([])\n",
    "    recall_list_NorBERT.append([])\n",
    "    precision_list_NorBERT_CNN.append([])\n",
    "    for _ in range(10000):\n",
    "        indices = random.sample(range(shape[0]), i)\n",
    "        # Create a new tensor with shape (2, 1264, 4)\n",
    "        new_tensor = np.zeros((i, shape[1], shape[2]))\n",
    "\n",
    "        # Assign the selected indices from all_logits to the new tensor\n",
    "        for j in range(i):\n",
    "            new_tensor[j] = all_logits[indices[j]]\n",
    "\n",
    "        bagging_logits = np.mean(new_tensor, axis=0)\n",
    "        bagging_predictions = np.argmax(bagging_logits, axis=1)\n",
    "   \n",
    "        f1 = f1_score(all_true_labels, bagging_predictions, average='macro')\n",
    "        ac = accuracy_score(all_true_labels, bagging_predictions)\n",
    "        recall = recall_score(all_true_labels, bagging_predictions, average='macro')\n",
    "        precision = precision_score(all_true_labels, bagging_predictions, average='macro')\n",
    "        f1_list_NorBERT_CNN[i-1].append(f1)\n",
    "        ac_list_NorBERT_CNn[i-1].append(ac)\n",
    "        recall_list_NorBERT[i-1].append(recall)\n",
    "        precision_list_NorBERT_CNN[i-1].append(precision)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list for plotting for Norbert and t5\n",
    "all_logits = np.concatenate((norbert_logits, t5_logits), axis=0)\n",
    "all_logits.shape\n",
    "# Get the shape of all_logits\n",
    "shape = all_logits.shape\n",
    "i =1\n",
    "f1_list_NorBERT_t5 = []\n",
    "ac_list_NorBERT_t5 = []\n",
    "recall_list_NorBERT_t5 = []\n",
    "precision_list_NorBERT_t5 = []\n",
    "\n",
    "# Select two random indices\n",
    "for i in range(1,16):\n",
    "    \n",
    "    f1_list_NorBERT_t5.append([])\n",
    "    ac_list_NorBERT_t5.append([])\n",
    "    recall_list_NorBERT_t5.append([])\n",
    "    precision_list_NorBERT_t5.append([])\n",
    "    for _ in range(10000):\n",
    "        indices = random.sample(range(shape[0]), i)\n",
    "        # Create a new tensor with shape (2, 1264, 4)\n",
    "        new_tensor = np.zeros((i, shape[1], shape[2]))\n",
    "\n",
    "        # Assign the selected indices from all_logits to the new tensor\n",
    "        for j in range(i):\n",
    "            new_tensor[j] = all_logits[indices[j]]\n",
    "\n",
    "        bagging_logits = np.mean(new_tensor, axis=0)\n",
    "        bagging_predictions = np.argmax(bagging_logits, axis=1)\n",
    "   \n",
    "        f1 = f1_score(all_true_labels, bagging_predictions, average='macro')\n",
    "        ac = accuracy_score(all_true_labels, bagging_predictions)\n",
    "        recall = recall_score(all_true_labels, bagging_predictions, average='macro')\n",
    "        precision = precision_score(all_true_labels, bagging_predictions, average='macro')\n",
    "        f1_list_NorBERT_t5[i-1].append(f1)\n",
    "        ac_list_NorBERT_t5[i-1].append(ac)\n",
    "        recall_list_NorBERT_t5[i-1].append(recall)\n",
    "        precision_list_NorBERT_t5[i-1].append(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list for plotting for t5 and bigru\n",
    "all_logits = np.concatenate((t5_logits, bigru_logits), axis=0)\n",
    "all_logits.shape\n",
    "# Get the shape of all_logits\n",
    "shape = all_logits.shape\n",
    "i =1\n",
    "f1_list_t5_bigru = []\n",
    "ac_list_t5_bigru = []\n",
    "recall_list_t5_bigru = []\n",
    "precision_list_t5_bigru = []\n",
    "\n",
    "# Select two random indices\n",
    "\n",
    "for i in range(1,16):\n",
    "        \n",
    "        f1_list_t5_bigru.append([])\n",
    "        ac_list_t5_bigru.append([])\n",
    "        recall_list_t5_bigru.append([])\n",
    "        precision_list_t5_bigru.append([])\n",
    "        for _ in range(10000):\n",
    "            indices = random.sample(range(shape[0]), i)\n",
    "            # Create a new tensor with shape (2, 1264, 4)\n",
    "            new_tensor = np.zeros((i, shape[1], shape[2]))\n",
    "    \n",
    "            # Assign the selected indices from all_logits to the new tensor\n",
    "            for j in range(i):\n",
    "                new_tensor[j] = all_logits[indices[j]]\n",
    "    \n",
    "            bagging_logits = np.mean(new_tensor, axis=0)\n",
    "            bagging_predictions = np.argmax(bagging_logits, axis=1)\n",
    "    \n",
    "            f1 = f1_score(all_true_labels, bagging_predictions, average='macro')\n",
    "            ac = accuracy_score(all_true_labels, bagging_predictions)\n",
    "            recall = recall_score(all_true_labels, bagging_predictions, average='macro')\n",
    "            precision = precision_score(all_true_labels, bagging_predictions, average='macro')\n",
    "            f1_list_t5_bigru[i-1].append(f1)\n",
    "            ac_list_t5_bigru[i-1].append(ac)\n",
    "            recall_list_t5_bigru[i-1].append(recall)\n",
    "            precision_list_t5_bigru[i-1].append(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list for plotting for t5 and CNN\n",
    "all_logits = np.concatenate((t5_logits, CNN_logits), axis=0)\n",
    "all_logits.shape\n",
    "# Get the shape of all_logits\n",
    "shape = all_logits.shape\n",
    "i =1\n",
    "f1_list_t5_CNN = []\n",
    "ac_list_t5_CNN = []\n",
    "recall_list_t5_CNN = []\n",
    "precision_list_t5_CNN = []\n",
    "\n",
    "# Select two random indices\n",
    "\n",
    "for i in range(1,16):\n",
    "    \n",
    "    f1_list_t5_CNN.append([])\n",
    "    ac_list_t5_CNN.append([])\n",
    "    recall_list_t5_CNN.append([])\n",
    "    precision_list_t5_CNN.append([])\n",
    "    for _ in range(10000):\n",
    "        indices = random.sample(range(shape[0]), i)\n",
    "        # Create a new tensor with shape (2, 1264, 4)\n",
    "        new_tensor = np.zeros((i, shape[1], shape[2]))\n",
    "\n",
    "        # Assign the selected indices from all_logits to the new tensor\n",
    "        for j in range(i):\n",
    "            new_tensor[j] = all_logits[indices[j]]\n",
    "\n",
    "        bagging_logits = np.mean(new_tensor, axis=0)\n",
    "        bagging_predictions = np.argmax(bagging_logits, axis=1)\n",
    "\n",
    "        f1 = f1_score(all_true_labels, bagging_predictions, average='macro')\n",
    "        ac = accuracy_score(all_true_labels, bagging_predictions)\n",
    "        recall = recall_score(all_true_labels, bagging_predictions, average='macro')\n",
    "        precision = precision_score(all_true_labels, bagging_predictions, average='macro')\n",
    "        f1_list_t5_CNN[i-1].append(f1)\n",
    "        ac_list_t5_CNN[i-1].append(ac)\n",
    "        recall_list_t5_CNN[i-1].append(recall)\n",
    "        precision_list_t5_CNN[i-1].append(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list for plotting for NorBERT, CNN, and t5\n",
    "all_logits = np.concatenate((norbert_logits, CNN_logits, t5_logits), axis=0)\n",
    "all_logits.shape\n",
    "# Get the shape of all_logits\n",
    "shape = all_logits.shape\n",
    "i =1\n",
    "f1_list_NorBERT_CNN_t5 = []\n",
    "ac_list_NorBERT_CNN_t5 = []\n",
    "recall_list_NorBERT_CNN_t5 = []\n",
    "precision_list_NorBERT_CNN_t5 = []\n",
    "\n",
    "# Select two random indices\n",
    "\n",
    "for i in range(1,16):\n",
    "        \n",
    "    f1_list_NorBERT_CNN_t5.append([])\n",
    "    ac_list_NorBERT_CNN_t5.append([])\n",
    "    recall_list_NorBERT_CNN_t5.append([])\n",
    "    precision_list_NorBERT_CNN_t5.append([])\n",
    "    for _ in range(10000):\n",
    "        indices = random.sample(range(shape[0]), i)\n",
    "        # Create a new tensor with shape (2, 1264, 4)\n",
    "        new_tensor = np.zeros((i, shape[1], shape[2]))\n",
    "\n",
    "        # Assign the selected indices from all_logits to the new tensor\n",
    "        for j in range(i):\n",
    "            new_tensor[j] = all_logits[indices[j]]\n",
    "\n",
    "        bagging_logits = np.mean(new_tensor, axis=0)\n",
    "        bagging_predictions = np.argmax(bagging_logits, axis=1)\n",
    "\n",
    "        f1 = f1_score(all_true_labels, bagging_predictions, average='macro')\n",
    "        ac = accuracy_score(all_true_labels, bagging_predictions)\n",
    "        recall = recall_score(all_true_labels, bagging_predictions, average='macro')\n",
    "        precision = precision_score(all_true_labels, bagging_predictions, average='macro')\n",
    "        f1_list_NorBERT_CNN_t5[i-1].append(f1)\n",
    "        ac_list_NorBERT_CNN_t5[i-1].append(ac)\n",
    "        recall_list_NorBERT_CNN_t5[i-1].append(recall)\n",
    "        precision_list_NorBERT_CNN_t5[i-1].append(precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list for plotting for NorBERT, BiGRU, and t5\n",
    "all_logits = np.concatenate((norbert_logits, bigru_logits, t5_logits), axis=0)\n",
    "all_logits.shape\n",
    "# Get the shape of all_logits\n",
    "shape = all_logits.shape\n",
    "i =1\n",
    "f1_list_NorBERT_BiGRU_t5 = []\n",
    "ac_list_NorBERT_BiGRU_t5 = []\n",
    "recall_list_NorBERT_BiGRU_t5 = []\n",
    "precision_list_NorBERT_BiGRU_t5 = []\n",
    "\n",
    "# Select two random indices\n",
    "\n",
    "for i in range(1,16):\n",
    "            \n",
    "    f1_list_NorBERT_BiGRU_t5.append([])\n",
    "    ac_list_NorBERT_BiGRU_t5.append([])\n",
    "    recall_list_NorBERT_BiGRU_t5.append([])\n",
    "    precision_list_NorBERT_BiGRU_t5.append([])\n",
    "    for _ in range(10000):\n",
    "        indices = random.sample(range(shape[0]), i)\n",
    "        # Create a new tensor with shape (2, 1264, 4)\n",
    "        new_tensor = np.zeros((i, shape[1], shape[2]))\n",
    "\n",
    "        # Assign the selected indices from all_logits to the new tensor\n",
    "        for j in range(i):\n",
    "            new_tensor[j] = all_logits[indices[j]]\n",
    "\n",
    "        bagging_logits = np.mean(new_tensor, axis=0)\n",
    "        bagging_predictions = np.argmax(bagging_logits, axis=1)\n",
    "\n",
    "        f1 = f1_score(all_true_labels, bagging_predictions, average='macro')\n",
    "        ac = accuracy_score(all_true_labels, bagging_predictions)\n",
    "        recall = recall_score(all_true_labels, bagging_predictions, average='macro')\n",
    "        precision = precision_score(all_true_labels, bagging_predictions, average='macro')\n",
    "        f1_list_NorBERT_BiGRU_t5[i-1].append(f1)\n",
    "        ac_list_NorBERT_BiGRU_t5[i-1].append(ac)\n",
    "        recall_list_NorBERT_BiGRU_t5[i-1].append(recall)\n",
    "        precision_list_NorBERT_BiGRU_t5[i-1].append(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list for plotting for NorBERT, BiGRU, and CNN, and t5\n",
    "all_logits = np.concatenate((norbert_logits, bigru_logits, CNN_logits, t5_logits), axis=0)\n",
    "all_logits.shape\n",
    "# Get the shape of all_logits\n",
    "shape = all_logits.shape\n",
    "i =1\n",
    "f1_list_NorBERT_BiGRU_CNN_t5 = []\n",
    "ac_list_NorBERT_BiGRU_CNN_t5 = []\n",
    "recall_list_NorBERT_BiGRU_CNN_t5 = []\n",
    "precision_list_NorBERT_BiGRU_CNN_t5 = []\n",
    "\n",
    "# Select two random indices\n",
    "\n",
    "for i in range(1,16):\n",
    "        \n",
    "    f1_list_NorBERT_BiGRU_CNN_t5.append([])\n",
    "    ac_list_NorBERT_BiGRU_CNN_t5.append([])\n",
    "    recall_list_NorBERT_BiGRU_CNN_t5.append([])\n",
    "    precision_list_NorBERT_BiGRU_CNN_t5.append([])\n",
    "    for _ in range(10000):\n",
    "        indices = random.sample(range(shape[0]), i)\n",
    "        # Create a new tensor with shape (2, 1264, 4)\n",
    "        new_tensor = np.zeros((i, shape[1], shape[2]))\n",
    "\n",
    "        # Assign the selected indices from all_logits to the new tensor\n",
    "        for j in range(i):\n",
    "            new_tensor[j] = all_logits[indices[j]]\n",
    "\n",
    "        bagging_logits = np.mean(new_tensor, axis=0)\n",
    "        bagging_predictions = np.argmax(bagging_logits, axis=1)\n",
    "\n",
    "        f1 = f1_score(all_true_labels, bagging_predictions, average='macro')\n",
    "        ac = accuracy_score(all_true_labels, bagging_predictions)\n",
    "        recall = recall_score(all_true_labels, bagging_predictions, average='macro')\n",
    "        precision = precision_score(all_true_labels, bagging_predictions, average='macro')\n",
    "        f1_list_NorBERT_BiGRU_CNN_t5[i-1].append(f1)\n",
    "        ac_list_NorBERT_BiGRU_CNN_t5[i-1].append(ac)\n",
    "        recall_list_NorBERT_BiGRU_CNN_t5[i-1].append(recall)\n",
    "        precision_list_NorBERT_BiGRU_CNN_t5[i-1].append(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list for plotting for NorBERT\n",
    "all_logits = norbert_logits\n",
    "all_logits.shape\n",
    "# Get the shape of all_logits\n",
    "shape = all_logits.shape\n",
    "i =1\n",
    "f1_list_NorBERT = []\n",
    "ac_list_NorBERT = []\n",
    "recall_list_NorBERT = []\n",
    "precision_list_NorBERT = []\n",
    "\n",
    "# Select two random indices\n",
    "\n",
    "for i in range(1,16):\n",
    "\n",
    "    f1_list_NorBERT.append([])\n",
    "    ac_list_NorBERT.append([])\n",
    "    recall_list_NorBERT.append([])\n",
    "    precision_list_NorBERT.append([])\n",
    "    for _ in range(10000):\n",
    "        indices = random.sample(range(shape[0]), i)\n",
    "        # Create a new tensor with shape (2, 1264, 4)\n",
    "        new_tensor = np.zeros((i, shape[1], shape[2]))\n",
    "\n",
    "        # Assign the selected indices from all_logits to the new tensor\n",
    "        for j in range(i):\n",
    "            new_tensor[j] = all_logits[indices[j]]\n",
    "\n",
    "        bagging_logits = np.mean(new_tensor, axis=0)\n",
    "        bagging_predictions = np.argmax(bagging_logits, axis=1)\n",
    "\n",
    "        f1 = f1_score(all_true_labels, bagging_predictions, average='macro')\n",
    "        ac = accuracy_score(all_true_labels, bagging_predictions)\n",
    "        recall = recall_score(all_true_labels, bagging_predictions, average='macro')\n",
    "        precision = precision_score(all_true_labels, bagging_predictions, average='macro')\n",
    "        f1_list_NorBERT[i-1].append(f1)\n",
    "        ac_list_NorBERT[i-1].append(ac)\n",
    "        recall_list_NorBERT[i-1].append(recall)\n",
    "        precision_list_NorBERT[i-1].append(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and std for NorBERT and CNN at 15 models\n",
    "for i in [f1_list_NorBERT_CNN[14],ac_list_NorBERT_CNn[14],recall_list_NorBERT[14],precision_list_NorBERT_CNN[14]]:\n",
    "    mean_list = []\n",
    "    std_list = []\n",
    "    mean = np.mean(i)*100\n",
    "    std = np.std(i)*100\n",
    "    mean_list.append(mean)\n",
    "    std_list.append(std)\n",
    "    print(f\"${mean:.4f}^{{\\pm{std:.4f}}}$ &\",end=\"\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and std for NorBERT and CNN at 5 models\n",
    "for i in [f1_list_NorBERT_CNN[4],ac_list_NorBERT_CNn[4],recall_list_NorBERT[4],precision_list_NorBERT_CNN[4]]:\n",
    "    mean_list = []\n",
    "    std_list = []\n",
    "    mean = np.mean(i)*100\n",
    "    std = np.std(i)*100\n",
    "    mean_list.append(mean)\n",
    "    std_list.append(std)\n",
    "    print(f\"${mean:.4f}^{{\\pm{std:.4f}}}$ &\",end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and std for NorBERT and t5 at 15 models\n",
    "for i in [f1_list_NorBERT_t5[14],ac_list_NorBERT_t5[14],recall_list_NorBERT_t5[14],precision_list_NorBERT_t5[14]]:\n",
    "    mean_list = []\n",
    "    std_list = []\n",
    "    mean = np.mean(i)*100\n",
    "    std = np.std(i)*100\n",
    "    mean_list.append(mean)\n",
    "    std_list.append(std)\n",
    "    print(f\"${mean:.4f}^{{\\pm{std:.4f}}}$ &\",end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and std for NorBERT and t5 at 5 models\n",
    "for i in [f1_list_NorBERT_t5[4],ac_list_NorBERT_t5[4],recall_list_NorBERT_t5[4],precision_list_NorBERT_t5[4]]:\n",
    "    mean_list = []\n",
    "    std_list = []\n",
    "    mean = np.mean(i)*100\n",
    "    std = np.std(i)*100\n",
    "    mean_list.append(mean)\n",
    "    std_list.append(std)\n",
    "    print(f\"${mean:.4f}^{{\\pm{std:.4f}}}$ &\",end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and std for t5 and bigru at 15 models\n",
    "for i in [f1_list_t5_bigru[14],ac_list_t5_bigru[14],recall_list_t5_bigru[14],precision_list_t5_bigru[14]]:\n",
    "    mean_list = []\n",
    "    std_list = []\n",
    "    mean = np.mean(i)*100\n",
    "    std = np.std(i)*100\n",
    "    mean_list.append(mean)\n",
    "    std_list.append(std)\n",
    "    print(f\"${mean:.4f}^{{\\pm{std:.4f}}}$ &\",end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and std for t5 and bigru at 5 models\n",
    "for i in [f1_list_t5_bigru[4],ac_list_t5_bigru[4],recall_list_t5_bigru[4],precision_list_t5_bigru[4]]:\n",
    "    mean_list = []\n",
    "    std_list = []\n",
    "    mean = np.mean(i)*100\n",
    "    std = np.std(i)*100\n",
    "    mean_list.append(mean)\n",
    "    std_list.append(std)\n",
    "    print(f\"${mean:.4f}^{{\\pm{std:.4f}}}$ &\",end=\"\")\n",
    "\n",
    "\n",
    "min(f1_list_t5_bigru[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and std for t5 and CNN at 15 models\n",
    "for i in [f1_list_t5_CNN[14],ac_list_t5_CNN[14],recall_list_t5_CNN[14],precision_list_t5_CNN[14]]:\n",
    "    mean_list = []\n",
    "    std_list = []\n",
    "    mean = np.mean(i)*100\n",
    "    std = np.std(i)*100\n",
    "    mean_list.append(mean)\n",
    "    std_list.append(std)\n",
    "    print(f\"${mean:.4f}^{{\\pm{std:.4f}}}$ &\",end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and std for t5 and CNN at 5 models\n",
    "for i in [f1_list_t5_CNN[4],ac_list_t5_CNN[4],recall_list_t5_CNN[4],precision_list_t5_CNN[4]]:\n",
    "    mean_list = []\n",
    "    std_list = []\n",
    "    mean = np.mean(i)*100\n",
    "    std = np.std(i)*100\n",
    "    mean_list.append(mean)\n",
    "    std_list.append(std)\n",
    "    print(f\"${mean:.4f}^{{\\pm{std:.4f}}}$ &\",end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and std for NorBERT, CNN, and t5 at 15 models\n",
    "for i in [f1_list_NorBERT_CNN_t5[14],ac_list_NorBERT_CNN_t5[14],recall_list_NorBERT_CNN_t5[14],precision_list_NorBERT_CNN_t5[14]]:\n",
    "    mean_list = []\n",
    "    std_list = []\n",
    "    mean = np.mean(i)*100\n",
    "    std = np.std(i)*100\n",
    "    mean_list.append(mean)\n",
    "    std_list.append(std)\n",
    "    print(f\"${mean:.4f}^{{\\pm{std:.4f}}}$ &\",end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and std for NorBERT, CNN, and t5 at 5 models\n",
    "for i in [f1_list_NorBERT_CNN_t5[4],ac_list_NorBERT_CNN_t5[4],recall_list_NorBERT_CNN_t5[4],precision_list_NorBERT_CNN_t5[4]]:\n",
    "    mean_list = []\n",
    "    std_list = []\n",
    "    mean = np.mean(i)*100\n",
    "    std = np.std(i)*100\n",
    "    mean_list.append(mean)\n",
    "    std_list.append(std)\n",
    "    print(f\"${mean:.4f}^{{\\pm{std:.4f}}}$ &\",end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "\n",
    "# plot for f1\n",
    "\n",
    "mean_list_norbert_cnn = np.mean(f1_list_NorBERT_CNN, axis=1)\n",
    "mean_list_norbert_t5 = np.mean(f1_list_NorBERT_t5, axis=1)\n",
    "mean_list_t5_bigru = np.mean(f1_list_t5_bigru, axis=1)\n",
    "mean_list_t5_cnn = np.mean(f1_list_t5_CNN, axis=1)\n",
    "mean_list_norbert_cnn_t5 = np.mean(f1_list_NorBERT_CNN_t5, axis=1)\n",
    "mean_list_norbert_bigru_t5 = np.mean(f1_list_NorBERT_BiGRU_t5, axis=1)\n",
    "mean_list_norbert_bigru_t5_cnn = np.mean(f1_list_NorBERT_BiGRU_CNN_t5, axis=1)\n",
    "mean_list_norbert = np.mean(f1_list_NorBERT, axis=1) \n",
    "\n",
    "\n",
    "df = pd.DataFrame(mean_list_norbert_cnn, columns = ['f1_norbert_cnn'])\n",
    "df['f1_norbert_t5'] = mean_list_norbert_t5\n",
    "df['f1_t5_bigru'] = mean_list_t5_bigru\n",
    "df['f1_t5_cnn'] = mean_list_t5_cnn\n",
    "df['f1_norbert_cnn_t5'] = mean_list_norbert_cnn_t5\n",
    "df['f1_norbert_bigru_t5'] = mean_list_norbert_bigru_t5\n",
    "df['f1_norbert_bigru_t5_cnn'] = mean_list_norbert_bigru_t5_cnn\n",
    "df['f1_norbert'] = mean_list_norbert\n",
    "df['Number Of Models In Ensemble'] = range(1,16)\n",
    "# font = lucida\n",
    "plt = px.line(df, x='Number Of Models In Ensemble', y='f1_norbert_cnn',title='F1 Macro Score Across Ensemble Sizes on Test Set of Mixed-Label Dataset',\n",
    "              labels={\"epoch\": \"Epoch\", \"f1\": \"F1 Score\"}, \n",
    "              template='plotly_white', width=1600, height=1000) \n",
    "# and label to the plot\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['f1_norbert'], mode='lines', name='NorBERT and NorBERT-CNN')\n",
    "plt.update_traces(line=dict(width=2.5, color='darkred'), \n",
    "                  mode='lines', \n",
    "                  marker=dict(size=8, color='LightSkyBlue', line=dict(width=2, color='DarkSlateGrey')))\n",
    "\n",
    "\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['f1_norbert_t5'], mode='lines', name='NorBERT and NorT5', line=dict(color='forestgreen', width=2.5))\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['f1_t5_bigru'], mode='lines', name='NorT5 and NorBERT-GRU')\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['f1_t5_cnn'], mode='lines', name='NorT5 and NorBERT-CNN', line=dict(color='black', width=2.5))\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['f1_norbert_cnn_t5'], mode='lines', name='NorBERT, NorBERT-CNN, and NorT5', line=dict(color='steelblue', width=2.5))\n",
    "\n",
    "\n",
    "plt.update_layout(title_font_size=30, title_x=0.5, xaxis_title='Number Of Models In Ensemble', yaxis_title='F1 Macro Score', font = dict(family='Times new roman', size = 30),\n",
    "                  xaxis_title_font=dict(family='Times new roman', size = 30), yaxis_title_font=dict(family='Times new roman', size = 30),\n",
    "                  xaxis_gridcolor='gray', yaxis_gridcolor='gray')\n",
    "#plt.to_image(format=\"png\", width=600, height=350, scale=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for accuracy\n",
    "\n",
    "mean_list_norbert_cnn = np.mean(ac_list_NorBERT_CNn, axis=1)\n",
    "mean_list_norbert_t5 = np.mean(ac_list_NorBERT_t5, axis=1)\n",
    "mean_list_t5_bigru = np.mean(ac_list_t5_bigru, axis=1)\n",
    "mean_list_t5_cnn = np.mean(ac_list_t5_CNN, axis=1)\n",
    "mean_list_norbert_cnn_t5 = np.mean(ac_list_NorBERT_CNN_t5, axis=1)\n",
    "mean_list_norbert_bigru_t5 = np.mean(ac_list_NorBERT_BiGRU_t5, axis=1)\n",
    "mean_list_norbert_bigru_t5_cnn = np.mean(ac_list_NorBERT_BiGRU_CNN_t5, axis=1)\n",
    "mean_list_norbert = np.mean(ac_list_NorBERT, axis=1)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(mean_list_norbert_cnn, columns = ['ac_norbert_cnn'])\n",
    "df['ac_norbert_t5'] = mean_list_norbert_t5\n",
    "df['ac_t5_bigru'] = mean_list_t5_bigru\n",
    "df['ac_t5_cnn'] = mean_list_t5_cnn\n",
    "df['ac_norbert_cnn_t5'] = mean_list_norbert_cnn_t5\n",
    "df['ac_norbert_bigru_t5'] = mean_list_norbert_bigru_t5\n",
    "df['ac_norbert_bigru_t5_cnn'] = mean_list_norbert_bigru_t5_cnn\n",
    "df['ac_norbert'] = mean_list_norbert\n",
    "df['Number Of Models In Ensemble'] = range(1,16)\n",
    "# font = lucida\n",
    "plt = px.line(df, x='Number Of Models In Ensemble', y='ac_norbert',title='Accuracy Across Ensemble Sizes on Test Set of Mixed-Label Dataset',\n",
    "              labels={\"epoch\": \"Epoch\", \"ac\": \"Accuracy\"}, \n",
    "              template='plotly_white', width=1600, height=1000)\n",
    "# and label to the plot\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['ac_norbert_cnn'], mode='lines', name='NorBERT and NorBERT-CNN')\n",
    "plt.update_traces(line=dict(width=2.5, color='darkred'), \n",
    "                  mode='lines', \n",
    "                  marker=dict(size=8, color='LightSkyBlue', line=dict(width=2, color='DarkSlateGrey')))\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['ac_norbert_t5'], mode='lines', name='NorBERT and NorT5', line=dict(color='forestgreen', width=2.5))\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['ac_t5_bigru'], mode='lines', name='NorT5 and NorBERT-GRU')\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['ac_t5_cnn'], mode='lines', name='NorT5 and NorBERT-CNN', line=dict(color='black', width=2.5))\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['ac_norbert_cnn_t5'], mode='lines', name='NorBERT, NorBERT-CNN, and NorT5', line=dict(color='steelblue', width=2.5))\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['ac_norbert_bigru_t5'], mode='lines', name='NorBERT, GRU, and T5')\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['ac_norbert_bigru_t5_cnn'], mode='lines', name='NorBERT, GRU, CNN, and T5', line=dict(color='purple', width=2.5))\n",
    "\n",
    "\n",
    "plt.update_layout(title_font_size=30, title_x=0.5, xaxis_title='Number Of Models In Ensemble', yaxis_title='Accuracy', font = dict(family='Times new roman', size = 30), \n",
    "                    xaxis_title_font=dict(family='Times new roman', size = 30), yaxis_title_font=dict(family='Times new roman', size = 30),\n",
    "                    xaxis_gridcolor='gray', yaxis_gridcolor='gray')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for recall\n",
    "\n",
    "mean_list_norbert_cnn = np.mean(recall_list_NorBERT, axis=1)\n",
    "mean_list_norbert_t5 = np.mean(recall_list_NorBERT_t5, axis=1)\n",
    "mean_list_t5_bigru = np.mean(recall_list_t5_bigru, axis=1)\n",
    "mean_list_t5_cnn = np.mean(recall_list_t5_CNN, axis=1)\n",
    "mean_list_norbert_cnn_t5 = np.mean(recall_list_NorBERT_CNN_t5, axis=1)\n",
    "mean_list_norbert_bigru_t5 = np.mean(recall_list_NorBERT_BiGRU_t5, axis=1)\n",
    "mean_list_norbert_bigru_t5_cnn = np.mean(recall_list_NorBERT_BiGRU_CNN_t5, axis=1)\n",
    "mean_list_norbert = np.mean(recall_list_NorBERT, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(mean_list_norbert_cnn, columns = ['recall_norbert_cnn'])\n",
    "df['recall_norbert_t5'] = mean_list_norbert_t5\n",
    "df['recall_t5_bigru'] = mean_list_t5_bigru\n",
    "df['recall_t5_cnn'] = mean_list_t5_cnn\n",
    "df['recall_norbert_cnn_t5'] = mean_list_norbert_cnn_t5\n",
    "df['recall_norbert_bigru_t5'] = mean_list_norbert_bigru_t5\n",
    "df['recall_norbert_bigru_t5_cnn'] = mean_list_norbert_bigru_t5_cnn\n",
    "df['recall_norbert'] = mean_list_norbert\n",
    "df['Number Of Models In Ensemble'] = range(1,16)\n",
    "# font = lucida\n",
    "plt = px.line(df, x='Number Of Models In Ensemble', y='recall_norbert',title='Recall Macro Score Across Ensemble Sizes on Test Set of Mixed-Label Dataset',\n",
    "              labels={\"epoch\": \"Epoch\", \"recall\": \"Recall\"}, \n",
    "              template='plotly_white', width=1600, height=1000)\n",
    "# and label to the plot\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['recall_norbert_cnn'], mode='lines', name='NorBERT and NorBERT-CNN')\n",
    "plt.update_traces(line=dict(width=2.5, color='darkred'), \n",
    "                  mode='lines', \n",
    "                  marker=dict(size=8, color='LightSkyBlue', line=dict(width=2, color='DarkSlateGrey')))\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['recall_norbert_t5'], mode='lines', name='NorBERT and T5', line=dict(color='forestgreen', width=2.5))\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['recall_t5_bigru'], mode='lines', name='NorT5 and NorBERT-GRU')\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['recall_t5_cnn'], mode='lines', name='NorT5 and NorBERT-CNN', line=dict(color='black', width=2.5))\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['recall_norbert_cnn_t5'], mode='lines', name='NorBERT, NorBERT-CNN, and NorT5', line=dict(color='steelblue', width=2.5))\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['recall_norbert_bigru_t5'], mode='lines', name='NorBERT, GRU, and T5')\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['recall_norbert_bigru_t5_cnn'], mode='lines', name='NorBERT, GRU, CNN, and T5', line=dict(color='purple', width=2.5))\n",
    "\n",
    "\n",
    "plt.update_layout(title_font_size=30, title_x=0.5, xaxis_title='Number Of Models In Ensemble', yaxis_title='Recall Macro Score', font = dict(family='Times new roman', size = 30),\n",
    "                    xaxis_title_font=dict(family='Times new roman', size = 30), yaxis_title_font=dict(family='Times new roman', size = 30),\n",
    "                    xaxis_gridcolor='gray', yaxis_gridcolor='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for precision\n",
    "\n",
    "mean_list_norbert_cnn = np.mean(precision_list_NorBERT_CNN, axis=1)\n",
    "mean_list_norbert_t5 = np.mean(precision_list_NorBERT_t5, axis=1)\n",
    "mean_list_t5_bigru = np.mean(precision_list_t5_bigru, axis=1)\n",
    "mean_list_t5_cnn = np.mean(precision_list_t5_CNN, axis=1)\n",
    "mean_list_norbert_cnn_t5 = np.mean(precision_list_NorBERT_CNN_t5, axis=1)\n",
    "mean_list_norbert_bigru_t5 = np.mean(precision_list_NorBERT_BiGRU_t5, axis=1)\n",
    "mean_list_norbert_bigru_t5_cnn = np.mean(precision_list_NorBERT_BiGRU_CNN_t5, axis=1)\n",
    "mean_list_norbert = np.mean(precision_list_NorBERT, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(mean_list_norbert_cnn, columns = ['precision_norbert_cnn'])\n",
    "df['precision_norbert_t5'] = mean_list_norbert_t5\n",
    "df['precision_t5_bigru'] = mean_list_t5_bigru\n",
    "df['precision_t5_cnn'] = mean_list_t5_cnn\n",
    "df['precision_norbert_cnn_t5'] = mean_list_norbert_cnn_t5\n",
    "df['precision_norbert_bigru_t5'] = mean_list_norbert_bigru_t5\n",
    "df['precision_norbert_bigru_t5_cnn'] = mean_list_norbert_bigru_t5_cnn\n",
    "df['precision_norbert'] = mean_list_norbert\n",
    "df['Number Of Models In Ensemble'] = range(1,16)\n",
    "# font = lucida\n",
    "plt = px.line(df, x='Number Of Models In Ensemble', y='precision_norbert',title='Precision Across Ensemble Sizes on Test Set of Mixed-Label Dataset',\n",
    "              labels={\"epoch\": \"Epoch\", \"precision\": \"Precision\"}, \n",
    "              template='plotly_white', width=1600, height=1000)\n",
    "# and label to the plot\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['precision_norbert_cnn'], mode='lines', name='NorBERT and CNN')\n",
    "plt.update_traces(line=dict(width=2.5, color='darkred'), \n",
    "                  mode='lines', \n",
    "                  marker=dict(size=8, color='LightSkyBlue', line=dict(width=2, color='DarkSlateGrey')))\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['precision_norbert_t5'], mode='lines', name='NorBERT and T5', line=dict(color='forestgreen', width=2.5))\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['precision_t5_bigru'], mode='lines', name='T5 and NorBERT-GRU')\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['precision_t5_cnn'], mode='lines', name='T5 and NorBERT-CNN', line=dict(color='black', width=2.5))\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['precision_norbert_cnn_t5'], mode='lines', name='NorBERT, NorBERT-CNN, and NorT5', line=dict(color='steelblue', width=2.5))\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['precision_norbert_bigru_t5'], mode='lines', name='NorBERT, GRU, and T5')\n",
    "#plt.add_scatter(x=df['Number Of Models In Ensemble'], y=df['precision_norbert_bigru_t5_cnn'], mode='lines', name='NorBERT, GRU, CNN, and T5', line=dict(color='purple', width=2.5))\n",
    "\n",
    "\n",
    "plt.update_layout(title_font_size=30, title_x=0.5, xaxis_title='Number Of Models In Ensemble', yaxis_title='Precision Macro Score', font = dict(family='Times new roman', size = 30),\n",
    "                    xaxis_title_font=dict(family='Times new roman', size = 30), yaxis_title_font=dict(family='Times new roman', size = 30),\n",
    "                    xaxis_gridcolor='gray', yaxis_gridcolor='gray')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
