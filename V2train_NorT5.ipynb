{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf00378-a443-45f9-901f-67e1fad3fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "from datasets import load_dataset\n",
    "from datasets import DatasetDict\n",
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79d80f0",
   "metadata": {},
   "source": [
    "The program can work with any of the four datasets with minor modifications. This program is adapted for the relabeled version of the mixed-label dataset. The program is written and commented with the help of ChatGPT and Copilot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2824b3-f8c1-40ad-b0c8-9fab68963fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = load_dataset(\"Statistikkprosjekt/Mixed\")\n",
    "newDatasetTrain = []\n",
    "newDatasetValidation = []\n",
    "newDatasetTest = []\n",
    "\n",
    "for i in dataset[\"train\"]:\n",
    "    newDatasetTrain.append({'review': i[\"review\"], 'sentiment': str(i[\"polarity\"])})\n",
    "\n",
    "for i in dataset[\"validation\"]:\n",
    "    newDatasetValidation.append({'review': i[\"review\"], 'sentiment': str(i[\"polarity\"])})\n",
    "\n",
    "for i in dataset[\"test\"]:\n",
    "    newDatasetTest.append({'review': i[\"review\"], 'sentiment': str(i[\"polarity\"])})\n",
    "\n",
    "\n",
    "dataset[\"train\"] = Dataset.from_list(newDatasetTrain)\n",
    "dataset[\"validation\"] = Dataset.from_list(newDatasetValidation)\n",
    "dataset[\"test\"] = Dataset.from_list(newDatasetTest)\n",
    "\n",
    "type(dataset[\"train\"][0][\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a15ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = tokenizer = AutoTokenizer.from_pretrained(\"ltg/nort5-base\", trust_remote_code=True)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"review\"], padding=\"max_length\", truncation=True, max_length = 90, return_tensors=\"pt\")\n",
    "\n",
    "def tokenize_label_function(examples):\n",
    "    return tokenizer(examples[\"sentiment\"], truncation=True, max_length = 1, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99a2741",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM \n",
    "from transformers import get_scheduler\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "num_epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7a6897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a3a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learning_rates =  [3e-6 for i in range(15)]\n",
    "learning_rates = sorted(learning_rates,reverse=False)\n",
    "batch_sizes = [16 for model in learning_rates]\n",
    "hidden_dropout_rates = [0.3 for model in learning_rates]\n",
    "for i in range(len(learning_rates)):\n",
    "    print(\"\")\n",
    "    print(f\"Model {i+1}\")\n",
    "    last = 199\n",
    "    best = 199\n",
    "\n",
    "   \n",
    "    tokenized_datasets = dataset.map(tokenize_label_function, batched=True) \n",
    "    \n",
    "    tokenized_datasets = tokenized_datasets.rename_column(\"input_ids\", \"labels\")\n",
    "    tokenized_datasets = tokenized_datasets.remove_columns([\"token_type_ids\",\"attention_mask\",\"sentiment\"])\n",
    "    tokenized_datasets = tokenized_datasets.map(tokenize_function, batched=True)\n",
    "    tokenized_datasets = tokenized_datasets.remove_columns([\"review\",\"token_type_ids\"])\n",
    "    tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "\n",
    "    small_train_dataset = tokenized_datasets[\"train\"].shuffle()\n",
    "    small_eval_dataset = tokenized_datasets[\"validation\"]\n",
    "\n",
    "    \n",
    "    train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=batch_sizes[i])\n",
    "    eval_dataloader = DataLoader(small_eval_dataset, batch_size=30)\n",
    "    num_training_steps = num_epochs * len(train_dataloader)\n",
    "\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    \"ltg/nort5-large\", trust_remote_code=True, hidden_dropout_prob = hidden_dropout_rates[i])\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rates[i]) \n",
    "\n",
    "    lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "    model.to(device)\n",
    "\n",
    "   \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "    \n",
    "        average_loss = 0   \n",
    "        model.train()\n",
    "        for batch in train_dataloader:\n",
    "            \n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        total_loss = 0.0\n",
    "        total_samples = 0\n",
    "        for batch in eval_dataloader:\n",
    "                \n",
    "                batch = {k: v.to(device) for k, v in batch.items()}\n",
    "               \n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**batch)\n",
    "\n",
    "                logits = outputs.logits\n",
    "\n",
    "\n",
    "                total_loss += outputs.loss.item() * batch['labels'].size(0)  # Access size of 'images' tensor \n",
    "                total_samples += batch['labels'].size(0)\n",
    "\n",
    "\n",
    "            # Calculate average loss over all samples\n",
    "        average_loss = total_loss / total_samples\n",
    "        print(f'Evaluation Loss: {average_loss}')    \n",
    "\n",
    "        if average_loss < last:\n",
    "            \n",
    "            Counter = 0\n",
    "            if average_loss < best:\n",
    "                torch.save(model, f\"output/T5_{i}.pth\")\n",
    "                best = average_loss\n",
    "           \n",
    "        last = average_loss\n",
    "        Counter +=1\n",
    "        if Counter > 2:   \n",
    "                print(epoch)         \n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd1352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# Disable gradient computation during evaluation\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "\n",
    "        # Forward pass\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        # Calculate predictions\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "        # Collect predictions and labels\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = accuracy_score(all_labels, all_predictions)\n",
    "\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "# Display the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(all_labels), yticklabels=np.unique(all_labels))\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show() \n",
    "\n",
    "# Optionally, you can print a detailed classification report\n",
    "report = classification_report(all_labels, all_predictions)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4583e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentages for each true label\n",
    "total_true_labels = np.sum(conf_matrix, axis=1)\n",
    "percentages = (conf_matrix / total_true_labels[:, np.newaxis]) * 100\n",
    "\n",
    "# Replace NaN values with 0 (for cases where the true label count is 0)\n",
    "percentages = np.nan_to_num(percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ce2126",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(percentages, annot=True, fmt=\"f\", cmap=\"Blues\", xticklabels=np.unique(all_labels), yticklabels=np.unique(all_labels))\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
